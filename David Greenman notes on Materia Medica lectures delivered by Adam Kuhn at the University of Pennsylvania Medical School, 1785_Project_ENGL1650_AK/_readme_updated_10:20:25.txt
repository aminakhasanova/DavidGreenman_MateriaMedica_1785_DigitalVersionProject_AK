Author: David Greenman

Title: David Greenman notes on Materia Medica lectures delivered by Adam Kuhn at the University of Pennsylvania Medical School

Place of Publication: University of Pennsylvania Medical School, Philadelphia, PA

Date of Publication: 1785

Physical Location: Kislak Center for Special Collections, Rare Books and Manuscripts, Manuscripts, Ms. Codex 1866

Catalogue Entry: https://find.library.upenn.edu/catalog/9977203451503681?hld_id=resource_link_0 

Colenda Entry: https://colenda.library.upenn.edu/catalog/81431-p3pz51s9t

Explanation: 

When documenting metadata for this book, I recorded the “file_name” to match each metadata to the corresponding digital page/image and “unique_ID” to have a consistent organization of all the metadata that I collected for pages of the book that I choose to focus on. I included “creator” and “date” because I think they are basic but still important characteristics of any text when it comes to collecting information about them. “Language” was also recorded to keep track of the language used in each page just in case some other languages were introduced maybe through annotations in some of the pages. “Page_number (original)” was included to help identify which pages were numbered by the author and which pages were left out such as the index section at the end of the book. “Page_type” was used to make the structure of the notebook clearer and categorize different parts of the notebook into sections such as index, title, or owner’s notes. “Text_legibility” was used to note which pages are easier or harder to read due to smudges, markings, or just the handwriting itself. “Images_present” was used to note if any pages included illustrations which are important to know if the book contains any drawings or images. “Handwriting_type” was included to distinguish cursive from printed letters because some annotations were made in printed letters in some pages so this category helps to keep track of such annotations. “Medium_used” helps to keep track whether ink or pencil was used for the text and possible annotations. “Annotations_present” was used to keep track of any corrections or notes made by the original creator, owner, or library staff. “Overall_page_condition” and “page_edge_condition” categories were used to document the fragility, water damage, and torn/trimmed edges of the pages in order to help the readers have a better understanding of the physical state of the book if they don’t have access to the physical book. Lastly, “content_summary/keywords” was used to provide a brief idea of what each page is about. Overall, the goal of collecting these metadata was not only to allow the book to be read and understood online, but also help convey the fragility and varying conditions of the pages throughout the book, which can be difficult to understand from the images of the pages alone.

Extract & Clean Text

The book that I am working with for this project consists almost entirely of writings in cursive. I performed text extraction and cleaning on the 25 pages that I selected previously since the entire book contains over 400 pages. I mostly used Transkribus and ChatGPT for text extraction. During this process, I encountered errors with moderate to high frequency. Depending on the page, there were words that required correction either on every line or every other line. I did not come across a page that required no corrections at all. 

I think part of the reason for the high number of corrections may be that the author of the book made several orthographic errors in their writing. However, when extracting the text, ChatGPT often produced the words with correct spellings rather than preserving the original ones where the author made some mistakes. In some cases, it even generated synonyms instead of the actual words used by the author. Since I knew that the author frequently made spelling errors and because their cursive handwriting was difficult to read, I often found myself uncertain whether certain letters represented “e” or “i.” For example, in the word medicine, I was unsure whether I was misinterpreting the author’s handwriting or whether there was actually a spelling error. The author’s “e” and “i” often looked similar and they sometimes omitted the dot above the “i” which contributed to my confusion. The same applies to a few other cases.

Also, some pages especially toward the end of the book, showed signs of physical damage with the edges torn and worn, causing some words to be cut off. In such cases, I chose to preserve the truncated versions of the words in the transcription in order to represent the condition of the original manuscript. However, ChatGPT tended to complete the cut off words through assumption.

Furthermore, for pages that included handwritten page numbers in the top right corner, ChatGPT’s transcription omitted these numbers. Therefore, I added them manually wherever they appeared and were visible. Some annotations written in pencil and sideways along the inner margins of the pages were not transcribed because I was not sure how to reproduce sideways text within a plain text file. 

Lastly, the quality of the scanned images may also have influenced the extraction process. It was often difficult to determine where the author had used a period. Commas were more easily identifiable but there were many instances in which words were unexpectedly capitalized without an obvious period before it. I believe this could have been due to the author’s handwriting style, in which punctuation marks were often connected to the last letter of the preceding word rather than standing separately on their own.

Overall, based on the frequency of errors and the number of times words were completely incorrect for my text at least, I believe it is essential to devote careful attention and time to cleaning the extracted text. Otherwise, readers of the transcribed files might frequently find the content confusing or inaccurate. It might be a good idea to determine a threshold of error frequency above which a text needs a detailed manual correction and below which automated extraction might sufficient.

However, I believe that the decision on whether to invest in paying someone for manual text cleaning should depend on the intended use of the text and its importance. If the content of the book (ex:word choice, orthography, sentence structure) is important, then the effort to carefully and manually clean the text might be justifiable.

